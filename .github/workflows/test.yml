name: Continuous Integration

on:
  push:
    branches: [main, dev, dev-no-puppets]
    paths:
      - 'src/**'
      - 'tests/**'
      - 'pyproject.toml'
      - 'uv.lock'
      - '.github/workflows/test.yml'
      - '.gitmodules'
      - 'submodules/**'
      - 'scripts/safeguards/**'
  pull_request:
    branches: [main, dev, dev-no-puppets]
    paths:
      - 'src/**'
      - 'tests/**'
      - 'pyproject.toml'
      - 'uv.lock'
      - '.github/workflows/test.yml'
      - '.gitmodules'
      - 'submodules/**'
      - 'scripts/safeguards/**'
  workflow_dispatch:
    inputs:
      test-scope:
        description: 'Test scope'
        required: false
        default: 'standard'
        type: choice
        options:
          - 'quick'        # Lint + basic tests only
          - 'standard'     # Default: lint, test, integration, build, integrity
          - 'comprehensive' # All tests including performance, security, ecosystem, Docker
      python-versions:
        description: 'Python versions to test (comma-separated)'
        required: false
        default: '3.11,3.12'
        type: string
      os-matrix:
        description: 'Operating systems to test (comma-separated)'
        required: false
        default: 'ubuntu-latest,windows-latest,macos-latest'
        type: string
      include-docker:
        description: 'Include Docker engine tests'
        required: false
        default: false
        type: boolean
      deep-validation:
        description: 'Run deep repository integrity validation'
        required: false
        default: false
        type: boolean

permissions:
  contents: read
  actions: write  # needed for workflow dispatch
  checks: write   # needed for test reporting

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

env:
  FORCE_COLOR: 1
  PIP_DISABLE_PIP_VERSION_CHECK: 1
  PYTHONIOENCODING: utf-8
  PYTHONUTF8: 1
  DOCKER_BUILDKIT: 1
  # Resource optimization for GitHub Actions compliance
  RESOURCE_CONSTRAINED: true
  # Additional resource constraints
  UV_NO_PROGRESS: 1
  UV_COMPILE_BYTECODE: 1
  GITHUB_ACTIONS_CPU_LIMIT: 2
  # Prevent resource abuse
  MAX_CONCURRENT_JOBS: 2
  WORKFLOW_TIMEOUT_MINUTES: 120

jobs:
  setup:
    name: Setup Configuration
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      test-scope: ${{ steps.config.outputs.test-scope }}
      python-versions: ${{ steps.config.outputs.python-versions }}
      os-matrix: ${{ steps.config.outputs.os-matrix }}
      test-matrix: ${{ steps.config.outputs.test-matrix }}
      run-comprehensive: ${{ steps.config.outputs.run-comprehensive }}
      run-ecosystem: ${{ steps.config.outputs.run-ecosystem }}
      run-docker: ${{ steps.config.outputs.run-docker }}
      deep-validation: ${{ steps.config.outputs.deep-validation }}

    steps:
      - name: Configure test parameters
        id: config
        shell: bash
        run: |
          # Determine test scope
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            test_scope="${{ inputs.test-scope }}"
            python_versions="${{ inputs.python-versions }}"
            os_matrix="${{ inputs.os-matrix }}"
            run_ecosystem="false"
          else
            # Auto-triggered (push/PR) - use standard scope with minimal matrix for cache efficiency
            test_scope="standard"
            python_versions="3.11"  # Single version to minimize cache footprint
            # Ultra-minimal matrix to drastically reduce cache usage
            if [[ "$GITHUB_EVENT_NAME" == "pull_request" ]]; then
              os_matrix="ubuntu-latest"  # Only Ubuntu for PRs
            else
              # Only test Ubuntu on pushes to main/dev - manual workflow dispatch for full matrix
              os_matrix="ubuntu-latest"
            fi
            run_ecosystem="false"
          fi

          echo "test-scope=$test_scope" >> $GITHUB_OUTPUT

          # Parse Python versions
          python_array=$(echo "$python_versions" | python3 -c "
          import sys, json
          versions = [v.strip() for v in sys.stdin.read().strip().split(',') if v.strip()]
          print(json.dumps(versions))
          ")
          echo "python-versions=$python_array" >> $GITHUB_OUTPUT

          # Parse OS matrix
          os_array=$(echo "$os_matrix" | python3 -c "
          import sys, json
          oses = [os.strip() for os in sys.stdin.read().strip().split(',') if os.strip()]
          print(json.dumps(oses))
          ")
          echo "os-matrix=$os_array" >> $GITHUB_OUTPUT

          # Create test matrix
          echo "test-matrix={\"os\": $os_array, \"python-version\": $python_array}" >> $GITHUB_OUTPUT

          # Set comprehensive flag
          if [ "$test_scope" = "comprehensive" ]; then
            echo "run-comprehensive=true" >> $GITHUB_OUTPUT
          else
            echo "run-comprehensive=false" >> $GITHUB_OUTPUT
          fi

          echo "run-ecosystem=$run_ecosystem" >> $GITHUB_OUTPUT

          # Docker testing configuration
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            run_docker="${{ inputs.include-docker }}"
          else
            # Auto-run Docker tests for comprehensive scope or main branch pushes
            if [[ "$test_scope" == "comprehensive" ]] || [[ "$GITHUB_REF_NAME" == "main" ]]; then
              run_docker="true"
            else
              run_docker="false"
            fi
          fi
          echo "run-docker=$run_docker" >> $GITHUB_OUTPUT

          # Deep validation configuration
          if [ "${{ github.event_name }}" = "workflow_dispatch" ]; then
            deep_validation="${{ inputs.deep-validation }}"
          else
            # Auto-run deep validation for comprehensive scope
            if [[ "$test_scope" == "comprehensive" ]]; then
              deep_validation="true"
            else
              deep_validation="false"
            fi
          fi
          echo "deep-validation=$deep_validation" >> $GITHUB_OUTPUT

          # Summary
          echo "## Test Configuration" >> $GITHUB_STEP_SUMMARY
          echo "- **Test Scope**: $test_scope" >> $GITHUB_STEP_SUMMARY
          echo "- **Python Versions**: $python_versions" >> $GITHUB_STEP_SUMMARY
          echo "- **Operating Systems**: $os_matrix" >> $GITHUB_STEP_SUMMARY
          echo "- **Docker Testing**: $run_docker" >> $GITHUB_STEP_SUMMARY
          echo "- **Deep Validation**: $deep_validation" >> $GITHUB_STEP_SUMMARY
          echo "- **Ecosystem Testing**: $run_ecosystem" >> $GITHUB_STEP_SUMMARY

  # Lint and Type Checking
  lint-and-type-check:
    name: Lint & Type Check
    runs-on: ubuntu-latest
    needs: setup
    if: always() && needs.setup.result == 'success'
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup environment
        uses: ./.github/actions/setup-environment
        with:
          python-version: '3.11'

      - name: Run linting checks
        run: |
          echo "üîç Running linting checks (critical issues only)..."
          # Focus on critical issues: syntax errors, undefined names, and security issues
          uv run ruff check src/ tests/ --select=E9,F63,F7,F82 --output-format=github || echo "‚ö†Ô∏è Some linting issues found but continuing..."
          echo "‚úÖ Critical linting checks completed"

      - name: Check code formatting
        run: |
          echo "üîç Checking code formatting..."
          uv run ruff format --check src/ tests/
          echo "‚úÖ Code formatting is correct"

      - name: Run type checking
        continue-on-error: true  # Allow type checking to fail for now
        run: |
          echo "üîç Running type checking..."
          uv run mypy src/ --install-types --non-interactive || echo "‚ö†Ô∏è Type checking failed but continuing..."
          echo "‚úÖ Type checking completed (with warnings)"

      - name: Validate project configuration
        run: |
          echo "üîç Validating project configuration..."
          # Check pyproject.toml syntax
          python -c "import tomllib; tomllib.load(open('pyproject.toml', 'rb'))"
          echo "‚úÖ Project configuration is valid"

  # Repository Integrity Validation
  repository-integrity:
    name: Repository Integrity
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.test-scope != 'quick' && always() && needs.setup.result == 'success'
    timeout-minutes: 20

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
        with:
          # Fetch full history for comprehensive validation
          fetch-depth: 0
          # Initialize submodules for validation
          submodules: 'recursive'

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install system dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y jq

      - name: Make safeguard scripts executable
        run: |
          chmod +x scripts/safeguards/*.sh
          chmod +x scripts/safeguards/*.py

      - name: Validate submodule URLs and configuration
        run: |
          echo "::group::Validating .gitmodules configuration"

          # Check that .gitmodules exists and is valid
          if [[ ! -f .gitmodules ]]; then
            echo "::error::.gitmodules file not found!"
            exit 1
          fi

          echo "‚úÖ .gitmodules file exists"

          # Validate expected submodule URLs
          expected_repos=(
            "submodules/homebrew-rxiv-maker|https://github.com/henriqueslab/homebrew-rxiv-maker.git"
            "submodules/scoop-rxiv-maker|https://github.com/henriqueslab/scoop-rxiv-maker.git"
            "submodules/vscode-rxiv-maker|https://github.com/HenriquesLab/vscode-rxiv-maker.git"
          )

          for repo_info in "${expected_repos[@]}"; do
            path="${repo_info%%|*}"
            expected_url="${repo_info##*|}"

            actual_url=$(git config -f .gitmodules --get "submodule.${path}.url" || echo "")

            if [[ "$actual_url" != "$expected_url" ]]; then
              echo "::error::Submodule ${path} has incorrect URL: '${actual_url}' (expected: '${expected_url}')"
              exit 1
            else
              echo "‚úÖ Submodule ${path} URL is correct"
            fi
          done

          echo "::endgroup::"

      - name: Run submodule integrity validation
        run: |
          echo "::group::Running submodule integrity validation"
          scripts/safeguards/validate-submodules.sh
          echo "::endgroup::"

      - name: Run repository boundary validation
        run: |
          echo "::group::Running repository boundary validation"
          python scripts/safeguards/check-repo-boundaries.py
          echo "::endgroup::"

      - name: Validate submodule content signatures
        run: |
          echo "::group::Validating content signatures"

          # Check homebrew submodule
          if [[ -d "submodules/homebrew-rxiv-maker" ]]; then
            echo "Validating Homebrew submodule..."

            if [[ ! -f "submodules/homebrew-rxiv-maker/Formula/rxiv-maker.rb" ]]; then
              echo "::error::Homebrew submodule missing Formula/rxiv-maker.rb"
              exit 1
            fi

            # Check for contamination
            if find submodules/homebrew-rxiv-maker -name "*.py" -type f | grep -q .; then
              echo "::error::Homebrew submodule contaminated with Python files"
              find submodules/homebrew-rxiv-maker -name "*.py" -type f
              exit 1
            fi

            echo "‚úÖ Homebrew submodule is clean"
          fi

          # Check scoop submodule
          if [[ -d "submodules/scoop-rxiv-maker" ]]; then
            echo "Validating Scoop submodule..."

            if [[ ! -f "submodules/scoop-rxiv-maker/bucket/rxiv-maker.json" ]]; then
              echo "::error::Scoop submodule missing bucket/rxiv-maker.json"
              exit 1
            fi

            # Validate JSON syntax
            if ! jq empty submodules/scoop-rxiv-maker/bucket/rxiv-maker.json; then
              echo "::error::Scoop manifest JSON is invalid"
              exit 1
            fi

            # Check for contamination
            if find submodules/scoop-rxiv-maker -name "*.py" -type f | grep -q .; then
              echo "::error::Scoop submodule contaminated with Python files"
              find submodules/scoop-rxiv-maker -name "*.py" -type f
              exit 1
            fi

            echo "‚úÖ Scoop submodule is clean"
          fi

          # Check VSCode submodule
          if [[ -d "submodules/vscode-rxiv-maker" ]]; then
            echo "Validating VSCode submodule..."

            if [[ ! -f "submodules/vscode-rxiv-maker/package.json" ]]; then
              echo "::error::VSCode submodule missing package.json"
              exit 1
            fi

            if [[ ! -f "submodules/vscode-rxiv-maker/src/extension.ts" ]]; then
              echo "::error::VSCode submodule missing src/extension.ts"
              exit 1
            fi

            # Validate package.json is a VSCode extension
            if ! jq -e '.engines.vscode' submodules/vscode-rxiv-maker/package.json > /dev/null; then
              echo "::error::VSCode package.json missing vscode engine requirement"
              exit 1
            fi

            # Check for main repo contamination
            contamination_files=(
              "submodules/vscode-rxiv-maker/pyproject.toml"
              "submodules/vscode-rxiv-maker/Makefile"
              "submodules/vscode-rxiv-maker/src/rxiv_maker"
            )

            for file in "${contamination_files[@]}"; do
              if [[ -e "$file" ]]; then
                echo "::error::VSCode submodule contaminated with main repo files: $file"
                exit 1
              fi
            done

            echo "‚úÖ VSCode submodule is clean"
          fi

          echo "::endgroup::"

      - name: Check for reverse contamination
        run: |
          echo "::group::Checking for reverse contamination"

          # Main repo shouldn't have submodule-specific files
          contamination_patterns=(
            "Formula/*.rb:Homebrew"
            "bucket/*.json:Scoop"
            "src/extension.ts:VSCode"
            "*.tmLanguage.json:VSCode"
            ".vscodeignore:VSCode"
          )

          found_contamination=false

          for pattern_info in "${contamination_patterns[@]}"; do
            pattern="${pattern_info%%:*}"
            source="${pattern_info##*:}"

            # Find files matching pattern, excluding submodules directory
            if find . -path "./submodules" -prune -o -name "${pattern##*/}" -type f -print | grep -q .; then
              echo "::error::Main repository contaminated with ${source} files: ${pattern}"
              find . -path "./submodules" -prune -o -name "${pattern##*/}" -type f -print | head -5
              found_contamination=true
            fi
          done

          if [[ "$found_contamination" == "true" ]]; then
            exit 1
          fi

          echo "‚úÖ No reverse contamination detected"
          echo "::endgroup::"

      - name: Deep validation (if requested)
        if: needs.setup.outputs.deep-validation == 'true'
        run: |
          echo "::group::Running deep validation"

          # Check commit history for any signs of corruption
          echo "Checking recent commits for repository integrity..."

          # Look for commits that might indicate corruption
          suspicious_patterns=(
            "pyproject.toml.*submodules"
            "src/rxiv_maker.*submodules"
            "package.json.*submodules"
            "Formula.*src/"
          )

          for pattern in "${suspicious_patterns[@]}"; do
            if git log --oneline --since="30 days ago" | grep -i "$pattern"; then
              echo "::warning::Found potentially suspicious commit pattern: $pattern"
            fi
          done

          # Validate submodule commit consistency
          echo "Validating submodule commit consistency..."
          git submodule status

          echo "::endgroup::"

      - name: Generate integrity report
        if: always()
        run: |
          echo "::group::Repository Integrity Report"
          echo "Generated at: $(date -u '+%Y-%m-%d %H:%M:%S UTC')"
          echo ""
          echo "Submodule Status:"
          git submodule status || echo "No submodules or submodule command failed"
          echo ""
          echo "Repository Structure:"
          find submodules -type f -name "package.json" -o -name "*.rb" -o -name "*.json" | head -20
          echo ""
          echo "Recent .gitmodules changes:"
          git log --oneline -n 5 -- .gitmodules || echo "No recent .gitmodules changes"
          echo "::endgroup::"

  test:
    name: Tests (${{ matrix.os }}, Python ${{ matrix.python-version }})
    runs-on: ${{ matrix.os }}
    needs: setup
    if: always() && needs.setup.result == 'success'
    strategy:
      matrix: ${{ fromJson(needs.setup.outputs.test-matrix) }}
      fail-fast: false
      max-parallel: 1  # Minimize concurrent jobs to reduce cache pressure
    timeout-minutes: 25  # Reduced timeout for faster feedback on core tests only

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: recursive

      - name: Setup environment
        uses: ./.github/actions/setup-environment
        with:
          python-version: ${{ matrix.python-version }}
          cache-suffix: ${{ matrix.python-version }}  # Simplified cache key - no OS suffix to share cache

      - name: Run unit tests
        uses: ./.github/actions/test-execution
        with:
          test-type: unit
          python-version: ${{ matrix.python-version }}
          os: ${{ matrix.os }}
          upload-coverage: ${{ matrix.python-version == '3.11' && matrix.os == 'ubuntu-latest' }}

      - name: Upload test artifacts
        if: always()
        uses: ./.github/actions/artifact-management
        with:
          action: upload-test-results
          name: test-results-${{ matrix.os }}-${{ matrix.python-version }}
          matrix-os: ${{ matrix.os }}
          matrix-python: ${{ matrix.python-version }}

  integration:
    name: Integration Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [setup, test]
    if: needs.setup.outputs.test-scope != 'quick' && always() && needs.setup.result == 'success'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup environment
        uses: ./.github/actions/setup-environment
        with:
          python-version: '3.11'
          install-latex: 'true'

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          platforms: linux/amd64,linux/arm64

      - name: Setup Docker environment and pull base image
        run: |
          # Ensure Docker is running
          sudo systemctl start docker
          sudo systemctl enable docker

          # Configure Docker for testing
          echo "DOCKER_BUILDKIT=1" >> $GITHUB_ENV
          echo "RXIV_ENGINE=DOCKER" >> $GITHUB_ENV

          # Pull the rxiv-maker base image with pdflatex
          echo "üê≥ Pulling rxiv-maker base image with LaTeX..."
          if docker pull henriqueslab/rxiv-maker-base:latest; then
            echo "‚úÖ Base image pulled successfully"
            docker images henriqueslab/rxiv-maker-base:latest
          else
            echo "‚ùå Failed to pull base image, integration tests may fail"
            exit 1
          fi

          # Verify pdflatex is available in the Docker image
          echo "üîç Verifying pdflatex availability in Docker image..."
          if docker run --rm --memory="1g" --cpus="1.0" henriqueslab/rxiv-maker-base:latest pdflatex --version; then
            echo "‚úÖ pdflatex verified in Docker image"
          else
            echo "‚ùå pdflatex not found in Docker image"
            exit 1
          fi

      - name: Test manuscript generation workflow with Docker
        env:
          RXIV_ENGINE: DOCKER
        run: |
          echo "Testing manuscript generation with Docker engine..."
          mkdir -p test-workspace && cd test-workspace

          # Test initialization (doesn't require LaTeX)
          uv run rxiv init test-manuscript --no-interrupt || echo "Init command failed"

          if [ -d "test-manuscript" ]; then
            echo "‚úÖ Manuscript initialized successfully"
            cd test-manuscript

            # Test validation using Docker (should work with LaTeX in container)
            echo "Testing validation with Docker engine..."
            uv run rxiv validate --no-doi || echo "Validation failed - this is expected without Docker mode properly configured"

            # Test basic Docker functionality
            echo "Testing basic Docker engine detection..."
            uv run python -c "
            import sys, os
            sys.path.insert(0, '../../src')
            os.environ['RXIV_ENGINE'] = 'DOCKER'
            from rxiv_maker.docker.manager import get_docker_manager
            manager = get_docker_manager()
            print(f'Docker available: {manager.check_docker_available()}')
            "
            cd ..
          fi
          cd ..

      - name: Run integration tests
        uses: ./.github/actions/test-execution
        with:
          test-type: integration

  # Conda Environment Testing
  conda-tests:
    name: Conda Environment Tests
    runs-on: ubuntu-latest
    timeout-minutes: 30
    needs: [setup, test]
    if: needs.setup.outputs.test-scope == 'comprehensive' && always() && needs.setup.result == 'success'

    strategy:
      matrix:
        python-version: ["3.11", "3.12"]
        conda-backend: ["conda", "mamba"]
      fail-fast: false
      max-parallel: 2

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
          submodules: recursive

      - name: Setup Miniconda
        uses: conda-incubator/setup-miniconda@v3
        with:
          python-version: ${{ matrix.python-version }}
          mamba-version: "*"  # Install mamba for speed
          channels: conda-forge,defaults
          channel-priority: true
          activate-environment: rxiv-maker-test
          environment-file: .github/conda-environment.yml

      - name: Verify conda environment
        shell: bash -l {0}  # Use login shell to activate conda
        run: |
          echo "Testing conda environment detection..."
          conda info
          echo "CONDA_DEFAULT_ENV: $CONDA_DEFAULT_ENV"
          echo "CONDA_PREFIX: $CONDA_PREFIX"
          which python
          python --version

      - name: Install rxiv-maker with conda dependencies
        shell: bash -l {0}
        run: |
          echo "Installing dependencies with ${{ matrix.conda-backend }}..."
          # Install conda dependencies first
          ${{ matrix.conda-backend }} install -y nodejs r-base
          # Then install rxiv-maker with pip
          pip install -e .

      - name: Run conda-specific tests
        shell: bash -l {0}
        run: |
          echo "Running conda platform detection tests..."
          python -m pytest tests/unit/test_conda_platform_detection.py -v

          echo "Running conda installation manager tests..."
          python -m pytest tests/unit/test_conda_installation_manager.py -v

          echo "Running platform detector tests with conda focus..."
          python -m pytest tests/unit/test_platform_detector.py -v -k "conda"

      - name: Test dependency detection in conda environment
        shell: bash -l {0}
        run: |
          echo "Testing dependency checker in conda environment..."
          python -c "
          import sys
          sys.path.insert(0, 'src')
          from rxiv_maker.utils.dependency_checker import check_system_dependencies
          checker = check_system_dependencies(verbose=True)
          print(f'Found conda: {any(d.name == \"Conda/Mamba\" and d.found for d in checker.dependencies)}')
          print(f'Python detected: {any(d.name == \"Python\" and d.found for d in checker.dependencies)}')
          print(f'In conda env: {checker.platform.is_in_conda_env()}')
          "

      - name: Test basic CLI functionality in conda
        shell: bash -l {0}
        run: |
          echo "Testing basic rxiv-maker CLI in conda environment..."
          python -m rxiv_maker.cli version --detailed
          python -c "
          import sys
          sys.path.insert(0, 'src')
          from rxiv_maker.utils.platform import platform_detector
          print(f'Conda environment detected: {platform_detector.is_in_conda_env()}')
          print(f'Conda env name: {platform_detector.get_conda_env_name()}')
          print(f'Python command: {platform_detector.python_cmd}')
          "
  # Docker Engine Testing
  docker-tests:
    name: Docker Engine Tests
    runs-on: ubuntu-latest
    timeout-minutes: 45
    needs: [setup, test]
    if: needs.setup.outputs.run-docker == 'true' && always() && needs.setup.result == 'success'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup environment
        uses: ./.github/actions/setup-environment
        with:
          python-version: '3.11'
          install-latex: 'true'

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
        with:
          platforms: linux/amd64,linux/arm64

      - name: Setup Docker environment
        run: |
          # Ensure Docker is running with resource limits
          sudo systemctl start docker
          sudo systemctl enable docker

          # Configure Docker for testing with resource constraints
          echo "DOCKER_BUILDKIT=1" >> $GITHUB_ENV
          echo "RXIV_ENGINE=DOCKER" >> $GITHUB_ENV

          # Set Docker resource limits for CI
          echo "DOCKER_DEFAULT_MEMORY=1g" >> $GITHUB_ENV
          echo "DOCKER_DEFAULT_CPUS=1.0" >> $GITHUB_ENV

          # Clean up any existing containers/images to free space
          echo "üßπ Cleaning up Docker resources..."
          docker system prune -f --volumes || echo "Docker cleanup warning (expected)"

          # Check available Docker resources
          echo "üìä Docker system info:"
          docker system df || echo "Docker df unavailable"

          # Check if base image exists, try to pull it with timeout
          echo "üê≥ Checking for rxiv-maker base image..."
          timeout 300 docker pull henriqueslab/rxiv-maker-base:latest && {
            echo "‚úÖ Base image pulled successfully"
            docker images henriqueslab/rxiv-maker-base:latest

            # Verify pdflatex is available in the image with strict limits
            echo "üîç Verifying pdflatex in Docker image..."
            timeout 60 docker run --rm \
              --memory="512m" \
              --cpus="0.5" \
              --ulimit nofile=1024:1024 \
              henriqueslab/rxiv-maker-base:latest pdflatex --version | head -3
          } || {
            echo "‚ö†Ô∏è Base image pull failed or timed out, Docker tests may be limited"
          }

      - name: Test Docker engine functionality
        env:
          RXIV_ENGINE: DOCKER
        run: |
          echo "üß™ Testing Docker engine functionality..."

          # Test basic Docker integration
          echo "Testing basic Docker integration..."

          # Test that Docker manager can be created and is functional
          uv run python -c "
          import sys, os
          sys.path.insert(0, 'src')
          os.environ['RXIV_ENGINE'] = 'DOCKER'
          from rxiv_maker.docker.manager import get_docker_manager
          manager = get_docker_manager()
          print(f'Docker available: {manager.check_docker_available()}')

          # Test that pdflatex is accessible in Docker
          result = manager.run_command(['pdflatex', '--version'])
          print(f'pdflatex available: {result.returncode == 0}')
          if result.returncode == 0:
              print('pdflatex output:', result.stdout[:100])
          else:
              print('pdflatex error:', result.stderr)
          "

      - name: Run Docker-specific integration tests
        env:
          RXIV_ENGINE: DOCKER
        run: |
          echo "üîß Running Docker-specific integration tests..."

          # Run Docker engine tests with proper environment
          echo "Running Docker integration test 1..."
          uv run pytest tests/integration/test_example_manuscript.py::TestExampleManuscript::test_rxiv_pdf_example_manuscript_cli \
            --engine=docker -v -s --tb=short || echo "Docker test 1 failed (non-critical)"

          echo "Running Docker integration test 2..."
          uv run pytest tests/integration/test_validation_workflow.py::TestValidationWorkflow::test_makefile_validation_valid_manuscript \
            --engine=docker -v -s --tb=short || echo "Docker test 2 failed (non-critical)"

          # Test Docker LaTeX compilation directly
          echo "Testing Docker LaTeX compilation directly..."
          uv run python -c "
          import sys, os
          from pathlib import Path
          sys.path.insert(0, 'src')
          os.environ['RXIV_ENGINE'] = 'DOCKER'
          from rxiv_maker.docker.manager import get_docker_manager

          manager = get_docker_manager()

          # Create a simple test .tex file
          test_tex = Path('test_docker.tex')
          test_tex.write_text(r'''
          \documentclass{article}
          \begin{document}
          Hello Docker LaTeX!
          \end{document}
          ''')

          # Try to compile it with Docker
          result = manager.run_latex_compilation(test_tex, passes=1)
          if result and len(result) > 0:
              print(f'LaTeX compilation result: {result[0].returncode}')
              if result[0].returncode == 0:
                  print('‚úÖ Docker LaTeX compilation successful')
              else:
                  print('‚ùå Docker LaTeX compilation failed')
                  print('stderr:', result[0].stderr)
          else:
              print('‚ùå No compilation results')
          "

          # Test Docker image build if needed (light test)
          echo "Testing Docker image availability..."
          if ! docker image inspect henriqueslab/rxiv-maker-base:latest >/dev/null 2>&1; then
            echo "‚ö†Ô∏è Base image not available, Docker tests completed with limitations"
          else
            echo "‚úÖ Docker base image is available and ready"
          fi

      - name: Test Docker with local build (if base image unavailable)
        continue-on-error: true
        run: |
          if ! docker image inspect henriqueslab/rxiv-maker-base:latest >/dev/null 2>&1; then
            echo "üî® Testing with local Docker build..."

            # Check if Dockerfile exists for local testing
            if [[ -f "src/docker/images/base/Dockerfile" ]]; then
              echo "Building local test image..."
              docker build -t rxiv-maker-test:local src/docker/images/base/ || echo "Local build failed"

              if docker image inspect rxiv-maker-test:local >/dev/null 2>&1; then
                echo "‚úÖ Local Docker build successful"
                docker run --rm --memory="1g" --cpus="1.0" rxiv-maker-test:local python --version || echo "Local image test failed"
              fi
            else
              echo "‚ö†Ô∏è No Dockerfile found for local testing"
            fi
          fi

      - name: Upload Docker test results
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: docker-test-results
          path: |
            test-results/
            logs/
            docker-logs/
          retention-days: 3  # Very short retention for Docker logs to minimize storage

  build:
    name: Build & Test Distribution
    runs-on: ubuntu-latest
    timeout-minutes: 20
    needs: [setup, test]
    if: needs.setup.outputs.test-scope != 'quick' && always() && needs.setup.result == 'success'

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup environment
        uses: ./.github/actions/setup-environment
        with:
          python-version: '3.11'

      - name: Build package
        run: uv build

      - name: Test distribution
        run: |
          python -m pip install --upgrade pip
          python -m pip install dist/*.whl
          python -c "import rxiv_maker; print('‚úÖ Package imports successfully')"
          python -c "from rxiv_maker import __version__; print(f'Version: {__version__}')"

      - name: Upload build artifacts
        uses: ./.github/actions/artifact-management
        with:
          action: upload
          name: dist-${{ github.sha }}
          path: dist/

  security:
    name: Security Scan
    runs-on: ubuntu-latest
    needs: setup
    if: needs.setup.outputs.run-comprehensive == 'true' && always() && needs.setup.result == 'success'
    timeout-minutes: 15

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup environment
        uses: ./.github/actions/setup-environment
        with:
          python-version: '3.11'

      - name: Build package
        run: |
          uv build --wheel --out-dir dist/
          python -m pip install dist/*.whl

      - name: Run security scans
        uses: ./.github/actions/test-execution
        with:
          test-type: security

      - name: Upload security reports
        if: always()
        uses: ./.github/actions/artifact-management
        with:
          action: upload
          name: security-reports-${{ github.sha }}
          path: |
            bandit-report.json
            safety-report.json

  ecosystem:
    name: Ecosystem Testing
    runs-on: ${{ matrix.os }}
    needs: setup
    if: needs.setup.outputs.run-ecosystem == 'true' && always() && needs.setup.result == 'success'
    strategy:
      matrix:
        os: [ubuntu-latest]  # Reduced to prevent resource abuse
        include:
          - os: ubuntu-latest
            package-managers: "pypi"
      fail-fast: false
    timeout-minutes: 30

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Setup environment
        uses: ./.github/actions/setup-environment
        with:
          python-version: '3.11'
          install-latex: 'true'
          enable-cache: 'false'  # Disable cache for ecosystem tests to reduce cache pressure

      - name: Verify LaTeX installation
        run: |
          echo "üîç Verifying LaTeX installation on ${{ runner.os }}..."
          if [ "${{ runner.os }}" = "Linux" ]; then
            echo "Linux: Using Docker engine"
            echo "RXIV_ENGINE: $RXIV_ENGINE"
            # Verify Docker can run pdflatex
            if command -v docker >/dev/null 2>&1; then
              docker pull henriqueslab/rxiv-maker-base:latest || echo "Docker image not available"
              docker run --rm --memory="1g" --cpus="1.0" henriqueslab/rxiv-maker-base:latest pdflatex --version || echo "pdflatex via Docker not accessible"
            fi
          else
            echo "${{ runner.os }}: Using local LaTeX installation"
            echo "RXIV_ENGINE: $RXIV_ENGINE"
            # Verify local pdflatex
            if pdflatex --version >/dev/null 2>&1; then
              echo "‚úÖ pdflatex is accessible"
              pdflatex --version | head -1
            else
              echo "‚ùå pdflatex not accessible"
              echo "PATH: $PATH"
            fi
          fi
        shell: bash

      - name: Test PyPI installation
        if: contains(matrix.package-managers, 'pypi')
        run: |
          echo "üêç Testing PyPI installation..."
          python -m pip install --upgrade pip

          # Test current build
          python -m pip install build
          python -m build --wheel --outdir dist/
          python -m pip install dist/*.whl

          if rxiv --version; then
            echo "‚úÖ Local package installation successful"
          else
            echo "‚ùå Local package installation failed"
            exit 1
          fi

      - name: Test Homebrew installation
        if: contains(matrix.package-managers, 'homebrew') && runner.os == 'macOS'
        continue-on-error: true
        run: |
          echo "üç∫ Testing Homebrew tap availability..."
          if command -v brew &> /dev/null; then
            brew tap henriqueslab/rxiv-maker || echo "Tap not available (expected for new projects)"
          else
            echo "Homebrew not available in CI"
          fi

      - name: Test Scoop installation
        if: contains(matrix.package-managers, 'scoop') && runner.os == 'Windows'
        continue-on-error: true
        run: |
          Write-Host "ü™£ Testing Scoop bucket availability..."
          if (Get-Command scoop -ErrorAction SilentlyContinue) {
            try {
              scoop bucket add henriqueslab https://github.com/henriqueslab/scoop-rxiv-maker
              Write-Host "‚úÖ Bucket added successfully"
            } catch {
              Write-Host "Bucket not available (expected for new projects)"
            }
          } else {
            Write-Host "Scoop not available in CI"
          }
        shell: powershell

  # Check for version changes and trigger Docker sync
  docker-version-sync:
    name: Docker Version Sync
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [test]
    if: github.event_name == 'push' && (github.ref_name == 'main' || github.ref_name == 'dev-no-puppets') && always()

    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 2  # Need at least 2 commits to compare

      - name: Check for version file changes
        id: check-version
        run: |
          # Check if version file changed in this push
          if git diff --name-only HEAD~1 HEAD | grep -q "src/rxiv_maker/__version__.py"; then
            echo "Version file changed"

            # Get current version
            VERSION=$(python3 -c "
            import sys
            sys.path.insert(0, 'src')
            from rxiv_maker.__version__ import __version__
            print(__version__)
            ")

            # Get previous version if possible
            PREV_VERSION=$(git show HEAD~1:src/rxiv_maker/__version__.py | python3 -c "
            import sys
            exec(sys.stdin.read())
            print(__version__)
            " 2>/dev/null || echo "unknown")

            echo "Previous version: $PREV_VERSION"
            echo "Current version: $VERSION"
            echo "version=$VERSION" >> $GITHUB_OUTPUT

            if [ "$PREV_VERSION" != "$VERSION" ]; then
              echo "Version changed from $PREV_VERSION to $VERSION"
              echo "changed=true" >> $GITHUB_OUTPUT
            else
              echo "Version file changed but version is the same"
              echo "changed=false" >> $GITHUB_OUTPUT
            fi
          else
            echo "Version file not changed"
            echo "changed=false" >> $GITHUB_OUTPUT
          fi

      - name: Trigger Docker image build
        if: steps.check-version.outputs.changed == 'true'
        uses: actions/github-script@v7
        with:
          script: |
            console.log(`Triggering local Docker image build for version ${{ steps.check-version.outputs.version }}`);

            try {
              // Check if Docker build workflow exists before triggering
              const workflows = await github.rest.actions.listRepoWorkflows({
                owner: context.repo.owner,
                repo: context.repo.repo
              });

              const dockerWorkflow = workflows.data.workflows.find(w =>
                w.name.includes('Docker') || w.path.includes('docker')
              );

              if (dockerWorkflow) {
                console.log(`Found Docker workflow: ${dockerWorkflow.name}`);
                const result = await github.rest.actions.createWorkflowDispatch({
                  owner: context.repo.owner,
                  repo: context.repo.repo,
                  workflow_id: dockerWorkflow.id,
                  ref: 'main',
                  inputs: {
                    rxiv_version: '${{ steps.check-version.outputs.version }}',
                    tag: 'v${{ steps.check-version.outputs.version }}',
                    platforms: 'linux/amd64,linux/arm64'
                  }
                });
                console.log('‚úÖ Successfully triggered Docker image build');
                console.log(`Workflow dispatch ID: ${result.data.id || 'N/A'}`);
              } else {
                console.log('‚ÑπÔ∏è No Docker build workflow found, skipping Docker image build trigger');
              }
            } catch (error) {
              console.log('‚ö†Ô∏è Docker sync error:', error.message);
              console.log('Continuing with CI pipeline...');
            }

      - name: Docker sync notification
        if: steps.check-version.outputs.changed == 'true'
        run: |
          echo "## üê≥ Docker Version Sync Triggered" >> $GITHUB_STEP_SUMMARY
          echo "- **Version**: ${{ steps.check-version.outputs.version }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Action**: Triggered Docker image build" >> $GITHUB_STEP_SUMMARY
          echo "- **Branch**: ${{ github.ref_name }}" >> $GITHUB_STEP_SUMMARY

  summary:
    name: Test Summary
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs: [setup, lint-and-type-check, repository-integrity, test, integration, docker-tests, build, security, ecosystem, docker-version-sync]
    if: always()

    steps:
      - name: Generate summary
        run: |
          echo "# CI/CD Pipeline Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Test Scope**: ${{ needs.setup.outputs.test-scope }}" >> $GITHUB_STEP_SUMMARY
          echo "**Trigger**: ${{ github.event_name }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          # Job results
          jobs=(
            "lint-and-type-check:Lint & Type Check"
            "repository-integrity:Repository Integrity"
            "test:Unit Tests"
            "integration:Integration Tests"
            "docker-tests:Docker Engine Tests"
            "build:Build & Distribution"
            "security:Security Scan"
            "ecosystem:Ecosystem Testing"
            "docker-version-sync:Docker Version Sync"
          )

          for job_info in "${jobs[@]}"; do
            job_name="${job_info%%:*}"
            job_title="${job_info#*:}"

            # Get job result using needs context
            case $job_name in
              "lint-and-type-check") result="${{ needs.lint-and-type-check.result }}" ;;
              "repository-integrity") result="${{ needs.repository-integrity.result }}" ;;
              "test") result="${{ needs.test.result }}" ;;
              "integration") result="${{ needs.integration.result }}" ;;
              "docker-tests") result="${{ needs.docker-tests.result }}" ;;
              "build") result="${{ needs.build.result }}" ;;
              "security") result="${{ needs.security.result }}" ;;
              "ecosystem") result="${{ needs.ecosystem.result }}" ;;
              "docker-version-sync") result="${{ needs.docker-version-sync.result }}" ;;
            esac

            case $result in
              "success") echo "‚úÖ **$job_title**: Passed" >> $GITHUB_STEP_SUMMARY ;;
              "failure") echo "‚ùå **$job_title**: Failed" >> $GITHUB_STEP_SUMMARY ;;
              "cancelled") echo "‚ö†Ô∏è **$job_title**: Cancelled" >> $GITHUB_STEP_SUMMARY ;;
              "skipped") echo "‚è≠Ô∏è **$job_title**: Skipped" >> $GITHUB_STEP_SUMMARY ;;
              *) echo "‚ùì **$job_title**: $result" >> $GITHUB_STEP_SUMMARY ;;
            esac
          done

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Workflow Status**: ${{ job.status }}" >> $GITHUB_STEP_SUMMARY
